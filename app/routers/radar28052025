from fastapi import APIRouter, Depends, HTTPException
from sqlalchemy.orm import Session
from sqlalchemy import func
from uuid import UUID
from app import database, models
from dotenv import load_dotenv
import matplotlib.pyplot as plt
import matplotlib
import io
from fastapi.responses import StreamingResponse
import numpy as np
import openai
import os

# Configura matplotlib per headless server
matplotlib.use('Agg')

load_dotenv()

openai.api_key = os.getenv("OPENAI_API_KEY")
model = os.getenv("OPENAI_MODEL", "gpt-4")

router = APIRouter()

@router.get("/assessment/{session_id}/radar")
def radar_data(session_id: UUID, db: Session = Depends(database.get_db)):
    """Restituisce i dati aggregati per il radar chart"""
    try:
        results = (
            db.query(
                models.AssessmentResult.process,
                func.avg(models.AssessmentResult.score).label("avg_score")
            )
            .filter(models.AssessmentResult.session_id == session_id)
            .group_by(models.AssessmentResult.process)
            .all()
        )

        if not results:
            raise HTTPException(status_code=404, detail="No results found for this session")

        radar_output = []
        for process, avg_score in results:
            # Determina lo stato basandoti sul punteggio
            if avg_score >= 4:
                status = "OTTIMO"
                level = 5
            elif avg_score >= 3.5:
                status = "BUONO" 
                level = 4
            elif avg_score >= 2.5:
                status = "SUFFICIENTE"
                level = 3
            elif avg_score >= 2:
                status = "CARENTE"
                level = 2
            else:
                status = "CRITICO"
                level = 1

            radar_output.append({
                "process": process,
                "avg_score": round(avg_score, 2),
                "status": status,
                "level": level
            })

        return {
            "benchmarks": 4,
            "ratings": radar_output,
            "session_id": str(session_id),
            "total_processes": len(radar_output)
        }
        
    except Exception as e:
        print(f"‚ùå Errore in radar_data: {e}")
        raise HTTPException(status_code=500, detail=f"Errore nel calcolo dei dati radar: {str(e)}")

@router.get("/assessment/{session_id}/ai-suggestions")
def ai_suggestions(session_id: UUID, db: Session = Depends(database.get_db)):
    """Genera suggerimenti AI basati sui punti critici dell'assessment"""
    try:
        results = (
            db.query(
                models.AssessmentResult.process,
                models.AssessmentResult.category,
                models.AssessmentResult.dimension,
                models.AssessmentResult.score,
                models.AssessmentResult.note
            )
            .filter(models.AssessmentResult.session_id == session_id)
            .order_by(models.AssessmentResult.process, models.AssessmentResult.category)
            .all()
        )

        if not results:
            raise HTTPException(status_code=404, detail="No assessment results found")

        # Trova le aree critiche (punteggio < 3)
        critical_areas = [
            {
                "process": r.process,
                "category": r.category,
                "dimension": r.dimension,
                "score": r.score,
                "note": r.note
            }
            for r in results if r.score < 3
        ]

        if not critical_areas:
            return {
                "message": "Nessuna area critica rilevata. Tutti i punteggi sono accettabili.",
                "critical_count": 0,
                "suggestions": "üéâ Ottimo lavoro! Il vostro livello di digitalizzazione √® soddisfacente in tutte le aree valutate."
            }

        # Costruisci il prompt per OpenAI
        prompt = """Sei un assistente esperto in trasformazione digitale per aziende manifatturiere italiane.
Analizza i seguenti punti critici emersi da un assessment digitale 4.0. Fornisci suggerimenti concreti e pratici.

Punti critici identificati:
"""
        
        for item in critical_areas:
            prompt += f"\n- üî¥ [{item['process']}] {item['category']} ‚Üí {item['dimension']} (Punteggio: {item['score']}/5)\n"
            if item['note']:
                prompt += f"  üí¨ Nota: {item['note']}\n"

        prompt += """

Per ciascun punto critico, fornisci:
1. üéØ Azioni immediate (0-3 mesi)
2. üí∞ Investimenti minimi richiesti 
3. üìà Benefici attesi
4. üìä KPI da monitorare

Rispondi in italiano con un tono professionale ma accessibile."""

        try:
            if not openai.api_key:
                return {
                    "critical_count": len(critical_areas),
                    "suggestions": "‚ö†Ô∏è API OpenAI non configurata. Configurare OPENAI_API_KEY per ottenere suggerimenti personalizzati."
                }

            response = openai.chat.completions.create(
                model=model,
                messages=[
                    {"role": "system", "content": "Sei un esperto di trasformazione digitale per aziende manifatturiere italiane."},
                    {"role": "user", "content": prompt}
                ],
                max_tokens=2000,
                temperature=0.7
            )
            
            return {
                "critical_count": len(critical_areas),
                "suggestions": response.choices[0].message.content
            }
            
        except Exception as e:
            print(f"‚ùå Errore OpenAI: {e}")
            return {
                "critical_count": len(critical_areas),
                "suggestions": f"‚ö†Ô∏è Errore nel generare suggerimenti AI: {str(e)}"
            }
            
    except Exception as e:
        print(f"‚ùå Errore in ai_suggestions: {e}")
        raise HTTPException(status_code=500, detail=f"Errore nel generare suggerimenti: {str(e)}")

@router.get("/assessment/{session_id}/radar-image")
def radar_image(session_id: UUID, db: Session = Depends(database.get_db)):
    """Genera l'immagine del radar chart - VERSIONE CORRETTA"""
    try:
        print(f"üéØ Generando radar chart per sessione: {session_id}")
        
        results = (
            db.query(
                models.AssessmentResult.process,
                func.avg(models.AssessmentResult.score).label("avg_score")
            )
            .filter(models.AssessmentResult.session_id == session_id)
            .group_by(models.AssessmentResult.process)
            .all()
        )

        if not results:
            print(f"‚ùå Nessun risultato trovato per sessione {session_id}")
            raise HTTPException(status_code=404, detail="No results found for this session")

        # Estrai labels e values
        labels = [r[0] for r in results]
        values = [float(r[1]) for r in results]
        
        print(f"üìä Processi trovati: {len(labels)}")
        print(f"üìã Labels: {labels}")
        print(f"üìà Values: {values}")

        # CORREZIONE PRINCIPALE: Calcola angoli basandoti sui dati effettivi
        num_vars = len(labels)
        print(f"üî¢ Numero di variabili: {num_vars}")
        
        # Calcola gli angoli per il numero corretto di variabili
        angles = np.linspace(0, 2 * np.pi, num_vars, endpoint=False).tolist()
        
        # Chiudi il cerchio aggiungendo il primo elemento alla fine
        angles += angles[:1]
        labels += labels[:1]
        values += values[:1]
        
        print(f"üîÑ Dopo chiusura cerchio:")
        print(f"   Angles: {len(angles)} elementi")
        print(f"   Labels: {len(labels)} elementi") 
        print(f"   Values: {len(values)} elementi")

        # CONTROLLO DI SICUREZZA: Verifica lunghezze
        if len(angles) != len(values):
            print(f"‚ö†Ô∏è WARNING: Lunghezze diverse! angles={len(angles)}, values={len(values)}")
            min_len = min(len(angles), len(values))
            angles = angles[:min_len]
            values = values[:min_len]
            labels = labels[:min_len]
            print(f"üîß Corrette a lunghezza: {min_len}")

        # Crea il grafico radar
        fig, ax = plt.subplots(figsize=(10, 10), subplot_kw=dict(polar=True))
        
        # DISEGNA IL RADAR (ora con lunghezze corrette)
        ax.plot(angles, values, linewidth=3, linestyle='solid', color='#2E86AB', alpha=0.8)
        ax.fill(angles, values, alpha=0.25, color='#2E86AB')
        
        # Configura gli assi
        ax.set_yticks([1, 2, 3, 4, 5])
        ax.set_yticklabels(['1', '2', '3', '4', '5'], fontsize=10)
        ax.set_ylim(0, 5)
        
        # Configura le etichette (escludi duplicati)
        ax.set_xticks(angles[:-1])
        ax.set_xticklabels(labels[:-1], fontsize=12, fontweight='bold')
        
        # Stile
        ax.grid(True, alpha=0.3)
        ax.set_facecolor('white')
        ax.set_title("Digital Assessment 4.0 - Radar Chart", 
                    fontsize=16, fontweight='bold', pad=20, color='#1F4E79')

        # Salva in buffer
        buf = io.BytesIO()
        plt.savefig(buf, format="png", dpi=150, bbox_inches='tight', 
                   facecolor='white', edgecolor='none')
        plt.close(fig)
        buf.seek(0)

        print("‚úÖ Radar chart generato con successo")
        return StreamingResponse(buf, media_type="image/png")
        
    except Exception as e:
        print(f"üí• Errore in radar_image: {e}")
        import traceback
        traceback.print_exc()
        raise HTTPException(status_code=500, detail=f"Errore nella generazione del radar chart: {str(e)}")

@router.get("/assessment/{session_id}/summary")
def assessment_summary(session_id: UUID, db: Session = Depends(database.get_db)):
    """Restituisce un riepilogo completo dell'assessment"""
    try:
        # Statistiche generali
        total_questions = db.query(models.AssessmentResult).filter(
            models.AssessmentResult.session_id == session_id
        ).count()
        
        if total_questions == 0:
            raise HTTPException(status_code=404, detail="No assessment data found")
        
        # Media generale
        avg_score = db.query(func.avg(models.AssessmentResult.score)).filter(
            models.AssessmentResult.session_id == session_id
        ).scalar()
        
        # Distribuzione punteggi
        score_distribution = db.query(
            models.AssessmentResult.score,
            func.count(models.AssessmentResult.score).label('count')
        ).filter(
            models.AssessmentResult.session_id == session_id
        ).group_by(models.AssessmentResult.score).all()
        
        # Punteggi per processo
        process_scores = db.query(
            models.AssessmentResult.process,
            func.avg(models.AssessmentResult.score).label("avg_score"),
            func.count(models.AssessmentResult.score).label("question_count")
        ).filter(
            models.AssessmentResult.session_id == session_id
        ).group_by(models.AssessmentResult.process).all()
        
        return {
            "session_id": str(session_id),
            "total_questions": total_questions,
            "overall_score": round(float(avg_score), 2) if avg_score else 0,
            "score_distribution": [{"score": s, "count": c} for s, c in score_distribution],
            "process_breakdown": [
                {
                    "process": p,
                    "avg_score": round(float(avg), 2),
                    "question_count": count,
                    "percentage": round((float(avg) / 5) * 100, 1)
                }
                for p, avg, count in process_scores
            ]
        }
        
    except Exception as e:
        print(f"‚ùå Errore in assessment_summary: {e}")
        raise HTTPException(status_code=500, detail=f"Errore nel calcolo del riepilogo: {str(e)}")
